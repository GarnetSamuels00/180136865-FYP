{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33752c0",
   "metadata": {},
   "source": [
    "np.random.randn(2,3) will produce a standard normal distribution of values for whatever shape you pass in this exaample you would get a 2 by 3 array of random values \n",
    "\n",
    "make random tweaks to the last best known combination of weights and biases for the lowest loss value \n",
    "\n",
    "this is only suitable for verticle data sets and does not need deep learning \n",
    "\n",
    "for a spiral data set you need a non linear function\n",
    "local minimum is a problem that can be solved with calculus \n",
    "the impacts of weights and biases on the loss\n",
    "\n",
    "how to measure the impact that x has on y for a non linear function\n",
    "To calculate the slope the tangent line is used which is the instantaneous slope between two points that are infinitely close on a curve. This instantaneous slope can only be done on a continuous curve. two points on a curve can be aproximated. This will give us derivates.\n",
    "\n",
    "Numerical differentiation produces the numerical derivative \n",
    "The further away these two points are the larger the innaccuracy is likely to be this is why using extremly close points is better.\n",
    "\n",
    "y=mx+b\n",
    "\n",
    "Now the y intercept (b) now needs to be calculated\n",
    "b=y-mx\n",
    "b=y2 - approximate_derivative * x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b38a58d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: invalid syntax (1864674485.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Garnet\\AppData\\Local\\Temp\\ipykernel_15500\\1864674485.py\"\u001b[1;36m, line \u001b[1;32m35\u001b[0m\n\u001b[1;33m    f'where x = {x1} is {approximate derivative}'\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 2*x**2\n",
    "\n",
    "x= np.arrange (0, 50, 0.001)\n",
    "y = f(x)\n",
    "\n",
    "plt.plot (x, y)\n",
    "\n",
    "colors= ['k', 'g', 'r', 'b', 'c']\n",
    "\n",
    "def approximate_tangent_line (x, approximate_derivative, b):\n",
    "    return approximate_derivative*x + b\n",
    "\n",
    "for i in range (5):\n",
    "    p2_delta = 0.0001\n",
    "    x1 = i\n",
    "    x2 = x1+p2_delta\n",
    "    \n",
    "    yl= f(x1)\n",
    "    y2= f (x2)\n",
    "    \n",
    "    print ((x1, y1), (x2, y2))\n",
    "    \n",
    "    approximate_derivative (y2-yl)/(x2-x1)\n",
    "    b = y2 - approximate_derivative+x2\n",
    "    \n",
    "    to_plot [x1-0.9, x1, x1+0.9]\n",
    "    \n",
    "    plt.scatter (x1, yl, c-colors [i])\n",
    "    plt.plot (to_plot,\n",
    "        [approximate_tangent_line (point, approximate_derivative, b)\n",
    "            for point in to_plot],\n",
    "        —Å=colors[i])\n",
    "    print ('Approximate derivative for f(x)',\n",
    "       f'where x = {x1} is {approximate derivative}'\n",
    "plt.show()\n",
    "#running this to calculate the tangent line and the slopes of those tangent lines for each point along the way using numerical differentiation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403395d7",
   "metadata": {},
   "source": [
    "we are often adjusting millions or more parameters \n",
    "calculating derivatives using numerical differentiation would require multiple forward passes for a single weight or bias adjustment persample\n",
    "this would take a while because the delta for each neuron would have to be used and then a forward pass until all the neurons in that layer are cycled through. This is done for every single weight and bias individually. This would have to be done per-sample. Derivatives is better than doing things randomly however using derivatives in this way would be similar to brute forcing things making the rocess something that would work but be slower than ideal.\n",
    "Partial and analytical derivatives should be used "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
